{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "smaller-colon",
   "metadata": {},
   "source": [
    "# Analysis of Tweets from a full archival search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sunset-formula",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import join\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "wrapped-exploration",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = '../data/tweets'\n",
    "# see folder /queries for the corresponding .sh files that use twarc to query\n",
    "# tweets from the Twitter v2 API\n",
    "queries = [\n",
    "    '95vsWissZeitVG', # secondary relevance\n",
    "    'ACertainDegreeOfFlexibility', # secondary relevance\n",
    "    'bundestagswahl', # tertiary relevance\n",
    "    'DauerstellenFürDaueraufgaben', # secondary relevance\n",
    "    'ESC', # tertiary relevance\n",
    "    'euro', # tertiary relevance\n",
    "    'FristIstFrust', # secondary relevance\n",
    "    'HannaImBundestag', # primary relevance\n",
    "    'Hanna_Others', # secondary relevance, combination of IchBinNichtHanna, IchBinMelek and IchBinJelena\n",
    "    'IchBinHanna', # primary relevance\n",
    "    'IchBinJelena', # secondary relevance\n",
    "    'IchBinMelek', # secondary relevance\n",
    "    'IchBinNichtHanna', # secondary relevance\n",
    "    'video_url', # tertiary secondary relevance\n",
    "    'WissZeitVG' # secondary relevance\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-cheat",
   "metadata": {},
   "source": [
    "Note: if the Tweets have already been downloaded and the Tweet data exists in the folder ```data``` as compressed ```.jsonl``` files, you can skip the \"Query tweets\" and \"Compress data\" steps and start processing at \"Decompress data\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-architecture",
   "metadata": {},
   "source": [
    "## Collect Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-burner",
   "metadata": {},
   "source": [
    "### Query tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-sheriff",
   "metadata": {},
   "source": [
    "Note: the queries are saved in separate files. I do this to make the data collection process reproducible by saving the exact query parameters for every data file. Before being able to execute a `.sh` file, the file permissions have to be changed to add execution permissions  \n",
    "\n",
    "`chmod +x ./queries/query.sh`\n",
    "\n",
    "Then navigate to the `/queries` folder and run  \n",
    "\n",
    "`./query.sh`  \n",
    "\n",
    "Note: this can take a while, depending on the number of Tweets that need to be downloaded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-brick",
   "metadata": {},
   "source": [
    "### Compress data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-iceland",
   "metadata": {},
   "source": [
    "Note: under windows, .xz files can be decompressed for examply with [WinZIP](https://www.winzip.com/win/en/xz-file.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the parameter \"-k\" keeps the original file\n",
    "! xz -k ../data/tweets/95vsWissZeitVG.jsonl\n",
    "! xz -k ../data/tweets/ACertainDegreeOfFlexibility.jsonl\n",
    "#! xz -k ../data/tweets/bundestagswahl.jsonl\n",
    "! xz -k ../data/tweets/DauerstellenFürDaueraufgaben.jsonl\n",
    "#! xz -k ../data/tweets/ESC.jsonl\n",
    "#! xz -k ../data/tweets/euro.jsonl\n",
    "! xz -k ../data/tweets/FristIstFrust.jsonl\n",
    "! xz -k ../data/tweets/HannaImBundestag.jsonl\n",
    "! xz -k ../data/tweets/Hanna_Others.jsonl\n",
    "! xz -k ../data/tweets/IchBinHanna.jsonl\n",
    "! xz -k ../data/tweets/IchBinJelena.jsonl\n",
    "! xz -k ../data/tweets/IchBinMelek.jsonl\n",
    "! xz -k ../data/tweets/IchBinNichtHanna.jsonl\n",
    "! xz -k ../data/tweets/video_url.jsonl\n",
    "! xz -k ../data/tweets/WissZeitVG.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-moderator",
   "metadata": {},
   "source": [
    "### Decompress data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-casino",
   "metadata": {},
   "outputs": [],
   "source": [
    "! xz -d ../data/tweets/95vsWissZeitVG.jsonl.xz\n",
    "! xz -d ../data/tweets/ACertainDegreeOfFlexibility.jsonl.xz\n",
    "! xz -d ../data/tweets/bundestagswahl.jsonl.xz\n",
    "! xz -d ../data/tweets/ESC.jsonl.xz\n",
    "! xz -d ../data/tweets/euro.jsonl.xz\n",
    "! xz -d ../data/tweets/FristIstFrust.jsonl.xz\n",
    "! xz -d ../data/tweets/HannaImBundestag.jsonl.xz\n",
    "! xz -d ../data/tweets/Hanna_Others.jsonl.xz\n",
    "! xz -d ../data/tweets/IchBinHanna.jsonl.xz\n",
    "! xz -d ../data/tweets/IchBinJelena.jsonl.xz\n",
    "! xz -d ../data/tweets/IchBinMelek.jsonl.xz\n",
    "! xz -d ../data/tweets/IchBinNichtHanna.jsonl.xz\n",
    "! xz -d ../data/tweets/video_url.jsonl.xz\n",
    "! xz -d ../data/tweets/WissZeitVG.jsonl.xz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-cherry",
   "metadata": {},
   "source": [
    "### Convert to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-science",
   "metadata": {},
   "source": [
    "Removes duplicate tweets (by ID) but keeps referenced tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "excited-defendant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 21.3M/21.3M [00:07<00:00, 3.02MB/s]\n",
      "\n",
      "ℹ️\n",
      "Read 26950 tweets from 29 lines. \n",
      "13076 were referenced tweets, 12244 were duplicates.\n",
      "Wrote 14706 rows and output 89 of 89 input columns in the CSV.\n",
      "\n",
      "100%|██████████████████████████████████████| 19.3M/19.3M [00:06<00:00, 3.02MB/s]\n",
      "\n",
      "ℹ️\n",
      "Read 23443 tweets from 25 lines. \n",
      "11331 were referenced tweets, 10271 were duplicates.\n",
      "Wrote 13172 rows and output 89 of 89 input columns in the CSV.\n",
      "\n",
      "100%|████████████████████████████████████████| 455M/455M [01:59<00:00, 4.00MB/s]\n",
      "\n",
      "ℹ️\n",
      "Read 377626 tweets from 422 lines. \n",
      "172491 were referenced tweets, 146019 were duplicates.\n",
      "Wrote 231607 rows and output 89 of 89 input columns in the CSV.\n",
      "\n",
      "100%|████████████████████████████████████████| 745k/745k [00:00<00:00, 3.11MB/s]\n",
      "\n",
      "ℹ️\n",
      "Read 838 tweets from 1 lines. \n",
      "399 were referenced tweets, 337 were duplicates.\n",
      "Wrote 501 rows and output 89 of 89 input columns in the CSV.\n",
      "\n",
      "100%|████████████████████████████████████████| 105M/105M [00:18<00:00, 5.80MB/s]\n",
      "\n",
      "ℹ️\n",
      "Read 52325 tweets from 79 lines. \n",
      "14227 were referenced tweets, 12369 were duplicates.\n",
      "Wrote 39956 rows and output 89 of 89 input columns in the CSV.\n",
      "\n",
      "100%|██████████████████████████████████████| 23.9M/23.9M [00:07<00:00, 3.16MB/s]\n",
      "\n",
      "ℹ️\n",
      "Read 28459 tweets from 30 lines. \n",
      "13524 were referenced tweets, 12198 were duplicates.\n",
      "Wrote 16261 rows and output 89 of 89 input columns in the CSV.\n",
      "\n",
      "100%|██████████████████████████████████████| 9.84M/9.84M [00:03<00:00, 3.33MB/s]\n",
      "\n",
      "ℹ️\n",
      "Read 12148 tweets from 13 lines. \n",
      "5785 were referenced tweets, 5543 were duplicates.\n",
      "Wrote 6605 rows and output 89 of 89 input columns in the CSV.\n",
      "\n",
      "100%|██████████████████████████████████████| 88.1k/88.1k [00:00<00:00, 1.61MB/s]\n",
      "\n",
      "ℹ️\n",
      "Read 59 tweets from 1 lines. \n",
      "28 were referenced tweets, 12 were duplicates.\n",
      "Wrote 47 rows and output 89 of 89 input columns in the CSV.\n",
      "\n",
      "100%|████████████████████████████████████████| 107M/107M [00:30<00:00, 3.63MB/s]\n",
      "\n",
      "ℹ️\n",
      "Read 117944 tweets from 125 lines. \n",
      "56320 were referenced tweets, 54173 were duplicates.\n",
      "Wrote 63771 rows and output 89 of 89 input columns in the CSV.\n",
      "\n",
      "100%|████████████████████████████████████████| 124k/124k [00:00<00:00, 2.13MB/s]\n",
      "\n",
      "ℹ️\n",
      "Read 144 tweets from 1 lines. \n",
      "71 were referenced tweets, 69 were duplicates.\n",
      "Wrote 75 rows and output 89 of 89 input columns in the CSV.\n",
      "\n",
      "100%|██████████████████████████████████████| 97.3k/97.3k [00:00<00:00, 1.76MB/s]\n",
      "\n",
      "ℹ️\n",
      "Read 113 tweets from 1 lines. \n",
      "56 were referenced tweets, 55 were duplicates.\n",
      "Wrote 58 rows and output 89 of 89 input columns in the CSV.\n",
      "\n",
      "100%|██████████████████████████████████████| 48.2k/48.2k [00:00<00:00, 1.30MB/s]\n",
      "\n",
      "ℹ️\n",
      "Read 32 tweets from 1 lines. \n",
      "14 were referenced tweets, 6 were duplicates.\n",
      "Wrote 26 rows and output 89 of 89 input columns in the CSV.\n",
      "\n",
      "100%|██████████████████████████████████████| 2.21M/2.21M [00:00<00:00, 3.48MB/s]\n",
      "\n",
      "ℹ️\n",
      "Read 2769 tweets from 3 lines. \n",
      "1343 were referenced tweets, 1296 were duplicates.\n",
      "Wrote 1473 rows and output 89 of 89 input columns in the CSV.\n",
      "\n",
      "100%|██████████████████████████████████████| 23.3M/23.3M [00:07<00:00, 3.14MB/s]\n",
      "\n",
      "ℹ️\n",
      "Read 26723 tweets from 29 lines. \n",
      "12861 were referenced tweets, 11646 were duplicates.\n",
      "Wrote 15077 rows and output 89 of 89 input columns in the CSV.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! twarc2 csv ../data/tweets/95vsWissZeitVG.jsonl ../data/tweets/95vsWissZeitVG.csv\n",
    "! twarc2 csv ../data/tweets/ACertainDegreeOfFlexibility.jsonl ../data/tweets/ACertainDegreeOfFlexibility.csv\n",
    "! twarc2 csv ../data/tweets/bundestagswahl.jsonl ../data/tweets/bundestagswahl.csv\n",
    "! twarc2 csv ../data/tweets/DauerstellenFürDaueraufgaben.jsonl ../data/tweets/DauerstellenFürDaueraufgaben.csv\n",
    "! twarc2 csv ../data/tweets/ESC.jsonl ../data/tweets/ESC.csv\n",
    "#! twarc2 csv ../data/tweets/euro.jsonl ../data/euro.csv\n",
    "! twarc2 csv ../data/tweets/FristIstFrust.jsonl ../data/tweets/FristIstFrust.csv\n",
    "! twarc2 csv ../data/tweets/HannaImBundestag.jsonl ../data/tweets/HannaImBundestag.csv\n",
    "! twarc2 csv ../data/tweets/Hanna_Others.jsonl ../data/tweets/Hanna_Others.csv\n",
    "! twarc2 csv ../data/tweets/IchBinHanna.jsonl ../data/tweets/IchBinHanna.csv\n",
    "! twarc2 csv ../data/tweets/IchBinJelena.jsonl ../data/tweets/IchBinJelena.csv\n",
    "! twarc2 csv ../data/tweets/IchBinMelek.jsonl ../data/tweets/IchBinMelek.csv\n",
    "! twarc2 csv ../data/tweets/IchBinNichtHanna.jsonl ../data/tweets/IchBinNichtHanna.csv\n",
    "! twarc2 csv ../data/tweets/video_url.jsonl ../data/tweets/video_url.csv\n",
    "! twarc2 csv ../data/tweets/WissZeitVG.jsonl ../data/tweets/WissZeitVG.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-niagara",
   "metadata": {},
   "source": [
    "## Extract conversation IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "silver-manufacturer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversation_IDs(src, dst, filename, chunks=False, chunksize=1000):\n",
    "    try:\n",
    "        data = pd.read_csv(join(src, '{}.csv'.format(filename)), low_memory=False)\n",
    "    except FileNotFoundError:\n",
    "        print('WARNING: no tweets found for query \"{}\"'.format(query))\n",
    "        return\n",
    "    \n",
    "    conversationIDs = data['conversation_id'].dropna().astype(int).unique()\n",
    "    print('{}: There are {} Tweets from {} conversations'\\\n",
    "              .format(filename, len(data), len(conversationIDs)))\n",
    "    \n",
    "    if chunks:\n",
    "        N_chunks = len(conversationIDs) // chunksize\n",
    "        print(N_chunks)\n",
    "        for i in range(N_chunks):\n",
    "            ID_chunk = conversationIDs[i * chunksize : (i + 1) * chunksize]\n",
    "            np.savetxt(join(dst, '{}_ConversationIDs_{}_to_{}.txt'\\\n",
    "                .format(filename, i * chunksize, (i + 1) * chunksize)),\n",
    "                ID_chunk, fmt='%d')\n",
    "        np.savetxt(join(dst, '{}_ConversationIDs_{}_to_{}.txt'\\\n",
    "                .format(filename, N_chunks * chunksize, len(conversationIDs))),\n",
    "                conversationIDs[N_chunks * chunksize : ], fmt='%d')\n",
    "            \n",
    "    else:   \n",
    "        np.savetxt(join(dst, '{}_ConversationIDs.txt'.format(filename)),\n",
    "                   conversationIDs, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "decreased-lesbian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95vsWissZeitVG: There are 14706 Tweets from 13910 conversations\n",
      "ACertainDegreeOfFlexibility: There are 13172 Tweets from 12285 conversations\n",
      "bundestagswahl: There are 231607 Tweets from 209035 conversations\n",
      "DauerstellenFürDaueraufgaben: There are 501 Tweets from 462 conversations\n",
      "ESC: There are 39956 Tweets from 37594 conversations\n",
      "WARNING: no tweets found for query \"euro\"\n",
      "FristIstFrust: There are 16261 Tweets from 15351 conversations\n",
      "HannaImBundestag: There are 6605 Tweets from 6338 conversations\n",
      "Hanna_Others: There are 47 Tweets from 42 conversations\n",
      "IchBinHanna: There are 63771 Tweets from 59711 conversations\n",
      "IchBinJelena: There are 75 Tweets from 73 conversations\n",
      "IchBinMelek: There are 58 Tweets from 58 conversations\n",
      "IchBinNichtHanna: There are 26 Tweets from 22 conversations\n",
      "video_url: There are 1473 Tweets from 1423 conversations\n",
      "WissZeitVG: There are 15077 Tweets from 13740 conversations\n"
     ]
    }
   ],
   "source": [
    "dst = '../data/conversation_IDs'\n",
    "for query in queries:\n",
    "    get_conversation_IDs(src, dst, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-incidence",
   "metadata": {},
   "source": [
    "## Extract Tweet IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "aerial-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Tweet_IDs(src, dst, filename, chunks=False, chunksize=1000):\n",
    "    try:\n",
    "        data = pd.read_csv(join(src, '{}.csv'.format(filename)), low_memory=False)\n",
    "    except FileNotFoundError:\n",
    "        print('WARNING: no tweets found for query \"{}\"'.format(query))\n",
    "        return\n",
    "    \n",
    "    TweetIDs = data['id'].dropna().astype(int).unique()\n",
    "    print('{}: There are {} Tweets'\\\n",
    "              .format(filename, len(TweetIDs)))\n",
    "    \n",
    "    if chunks:\n",
    "        N_chunks = len(TweetIDs) // chunksize\n",
    "        print(N_chunks)\n",
    "        for i in range(N_chunks):\n",
    "            ID_chunk = TweetIDs[i * chunksize : (i + 1) * chunksize]\n",
    "            np.savetxt(join(dst, '{}_TweetIDs_{}_to_{}.txt'\\\n",
    "                .format(filename, i * chunksize, (i + 1) * chunksize)),\n",
    "                ID_chunk, fmt='%d')\n",
    "        np.savetxt(join(dst, '{}_TweetIDs_{}_to_{}.txt'\\\n",
    "                .format(filename, N_chunks * chunksize, len(TweetIDs))),\n",
    "                TweetIDs[N_chunks * chunksize : ], fmt='%d')\n",
    "            \n",
    "    else:   \n",
    "        np.savetxt(join(dst, '{}_TweetIDs.txt'.format(filename)),\n",
    "                   TweetIDs, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5a686e60-8bd2-4206-a67e-170c105db83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95vsWissZeitVG: There are 14706 Tweets\n",
      "ACertainDegreeOfFlexibility: There are 13172 Tweets\n",
      "bundestagswahl: There are 231607 Tweets\n",
      "DauerstellenFürDaueraufgaben: There are 501 Tweets\n",
      "ESC: There are 39956 Tweets\n",
      "WARNING: no tweets found for query \"euro\"\n",
      "FristIstFrust: There are 16261 Tweets\n",
      "HannaImBundestag: There are 6605 Tweets\n",
      "Hanna_Others: There are 47 Tweets\n",
      "IchBinHanna: There are 63771 Tweets\n",
      "IchBinJelena: There are 75 Tweets\n",
      "IchBinMelek: There are 58 Tweets\n",
      "IchBinNichtHanna: There are 26 Tweets\n",
      "video_url: There are 1473 Tweets\n",
      "WissZeitVG: There are 15077 Tweets\n"
     ]
    }
   ],
   "source": [
    "dst = '../data/tweet_IDs'\n",
    "for query in queries:\n",
    "    get_Tweet_IDs(src, dst, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a26da2-66b7-4c97-afbb-b7e17e96b08a",
   "metadata": {},
   "source": [
    "## Sanity check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "559c9d7c-3b82-4f73-8f50-816d0cf4666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hashtags(tagstring):\n",
    "    if tagstring == tagstring:\n",
    "        list_of_dicts = eval(tagstring)\n",
    "        hashtags = []\n",
    "        for dct in list_of_dicts:\n",
    "            tag = dct['tag']\n",
    "            hashtags.append(tag)\n",
    "        return hashtags\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def extract_reference_type(referencestring):\n",
    "    if referencestring == referencestring:\n",
    "        referencestring = referencestring.replace('false', 'False')\n",
    "        referencestring = referencestring.replace('true', 'True')\n",
    "        # almost all tweets reference a single other tweets. A minority reference\n",
    "        # more than one. In these cases we use the reference type of the first\n",
    "        # reference\n",
    "        dct = eval(referencestring)[0]\n",
    "        return dct['type']\n",
    "    else:\n",
    "        return 'no_reference'\n",
    "    \n",
    "def check_wanted_tag(tweet_tags):\n",
    "    if tweet_tags == tweet_tags: # nan-check\n",
    "        if len(wanted_tags.intersection(set(tweet_tags))) == 0:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "aa8427af-8fa0-4e43-8249-8742a620e735",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    '95vsWissZeitVG', # secondary relevance\n",
    "    'ACertainDegreeOfFlexibility', # secondary relevance\n",
    "    'DauerstellenFürDaueraufgaben', # secondary relevance\n",
    "    'FristIstFrust', # secondary relevance\n",
    "    'HannaImBundestag', # primary relevance\n",
    "    'Hanna_Others', # secondary relevance, combination of IchBinNichtHanna, IchBinMelek and IchBinJelena\n",
    "    'IchBinHanna', # primary relevance\n",
    "    'IchBinJelena', # secondary relevance\n",
    "    'IchBinMelek', # secondary relevance\n",
    "    'IchBinNichtHanna', # secondary relevance\n",
    "    'WissZeitVG' # secondary relevance\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6040c765-74d1-4f29-996f-4d33c25fa220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95vsWissZeitVG\n",
      "\t*************\n",
      "\treference type: no_reference\n",
      "\tNumber of tweets with a wanted tag: 835\n",
      "\tNumber of tweets without a wanted tag: 341\n",
      "\n",
      "\t*************\n",
      "\treference type: retweeted\n",
      "\tNumber of tweets with a wanted tag: 2629\n",
      "\tNumber of tweets without a wanted tag: 8795\n",
      "\n",
      "\t*************\n",
      "\treference type: replied_to\n",
      "\tNumber of tweets with a wanted tag: 536\n",
      "\tNumber of tweets without a wanted tag: 365\n",
      "\n",
      "\t*************\n",
      "\treference type: quoted\n",
      "\tNumber of tweets with a wanted tag: 1068\n",
      "\tNumber of tweets without a wanted tag: 137\n",
      "\n",
      "ACertainDegreeOfFlexibility\n",
      "\t*************\n",
      "\treference type: quoted\n",
      "\tNumber of tweets with a wanted tag: 1018\n",
      "\tNumber of tweets without a wanted tag: 190\n",
      "\n",
      "\t*************\n",
      "\treference type: retweeted\n",
      "\tNumber of tweets with a wanted tag: 2227\n",
      "\tNumber of tweets without a wanted tag: 7398\n",
      "\n",
      "\t*************\n",
      "\treference type: no_reference\n",
      "\tNumber of tweets with a wanted tag: 789\n",
      "\tNumber of tweets without a wanted tag: 488\n",
      "\n",
      "\t*************\n",
      "\treference type: replied_to\n",
      "\tNumber of tweets with a wanted tag: 660\n",
      "\tNumber of tweets without a wanted tag: 402\n",
      "\n",
      "DauerstellenFürDaueraufgaben\n",
      "\t*************\n",
      "\treference type: quoted\n",
      "\tNumber of tweets with a wanted tag: 33\n",
      "\tNumber of tweets without a wanted tag: 8\n",
      "\n",
      "\t*************\n",
      "\treference type: retweeted\n",
      "\tNumber of tweets with a wanted tag: 25\n",
      "\tNumber of tweets without a wanted tag: 307\n",
      "\n",
      "\t*************\n",
      "\treference type: no_reference\n",
      "\tNumber of tweets with a wanted tag: 43\n",
      "\tNumber of tweets without a wanted tag: 35\n",
      "\n",
      "\t*************\n",
      "\treference type: replied_to\n",
      "\tNumber of tweets with a wanted tag: 33\n",
      "\tNumber of tweets without a wanted tag: 17\n",
      "\n",
      "FristIstFrust\n",
      "\t*************\n",
      "\treference type: no_reference\n",
      "\tNumber of tweets with a wanted tag: 1425\n",
      "\tNumber of tweets without a wanted tag: 754\n",
      "\n",
      "\t*************\n",
      "\treference type: retweeted\n",
      "\tNumber of tweets with a wanted tag: 3146\n",
      "\tNumber of tweets without a wanted tag: 8495\n",
      "\n",
      "\t*************\n",
      "\treference type: quoted\n",
      "\tNumber of tweets with a wanted tag: 1164\n",
      "\tNumber of tweets without a wanted tag: 169\n",
      "\n",
      "\t*************\n",
      "\treference type: replied_to\n",
      "\tNumber of tweets with a wanted tag: 705\n",
      "\tNumber of tweets without a wanted tag: 403\n",
      "\n",
      "HannaImBundestag\n",
      "\t*************\n",
      "\treference type: quoted\n",
      "\tNumber of tweets with a wanted tag: 404\n",
      "\tNumber of tweets without a wanted tag: 65\n",
      "\n",
      "\t*************\n",
      "\treference type: retweeted\n",
      "\tNumber of tweets with a wanted tag: 2092\n",
      "\tNumber of tweets without a wanted tag: 3071\n",
      "\n",
      "\t*************\n",
      "\treference type: no_reference\n",
      "\tNumber of tweets with a wanted tag: 588\n",
      "\tNumber of tweets without a wanted tag: 98\n",
      "\n",
      "\t*************\n",
      "\treference type: replied_to\n",
      "\tNumber of tweets with a wanted tag: 208\n",
      "\tNumber of tweets without a wanted tag: 79\n",
      "\n",
      "Hanna_Others\n",
      "\t*************\n",
      "\treference type: no_reference\n",
      "\tNumber of tweets with a wanted tag: 0\n",
      "\tNumber of tweets without a wanted tag: 11\n",
      "\n",
      "\t*************\n",
      "\treference type: retweeted\n",
      "\tNumber of tweets with a wanted tag: 0\n",
      "\tNumber of tweets without a wanted tag: 24\n",
      "\n",
      "\t*************\n",
      "\treference type: quoted\n",
      "\tNumber of tweets with a wanted tag: 1\n",
      "\tNumber of tweets without a wanted tag: 1\n",
      "\n",
      "\t*************\n",
      "\treference type: replied_to\n",
      "\tNumber of tweets with a wanted tag: 0\n",
      "\tNumber of tweets without a wanted tag: 10\n",
      "\n",
      "IchBinHanna\n",
      "\t*************\n",
      "\treference type: quoted\n",
      "\tNumber of tweets with a wanted tag: 3858\n",
      "\tNumber of tweets without a wanted tag: 307\n",
      "\n",
      "\t*************\n",
      "\treference type: retweeted\n",
      "\tNumber of tweets with a wanted tag: 25099\n",
      "\tNumber of tweets without a wanted tag: 24459\n",
      "\n",
      "\t*************\n",
      "\treference type: no_reference\n",
      "\tNumber of tweets with a wanted tag: 5402\n",
      "\tNumber of tweets without a wanted tag: 546\n",
      "\n",
      "\t*************\n",
      "\treference type: replied_to\n",
      "\tNumber of tweets with a wanted tag: 2805\n",
      "\tNumber of tweets without a wanted tag: 1295\n",
      "\n",
      "IchBinJelena\n",
      "\t*************\n",
      "\treference type: no_reference\n",
      "\tNumber of tweets with a wanted tag: 2\n",
      "\tNumber of tweets without a wanted tag: 1\n",
      "\n",
      "\t*************\n",
      "\treference type: retweeted\n",
      "\tNumber of tweets with a wanted tag: 48\n",
      "\tNumber of tweets without a wanted tag: 21\n",
      "\n",
      "\t*************\n",
      "\treference type: quoted\n",
      "\tNumber of tweets with a wanted tag: 1\n",
      "\tNumber of tweets without a wanted tag: 0\n",
      "\n",
      "\t*************\n",
      "\treference type: replied_to\n",
      "\tNumber of tweets with a wanted tag: 1\n",
      "\tNumber of tweets without a wanted tag: 1\n",
      "\n",
      "IchBinMelek\n",
      "\t*************\n",
      "\treference type: no_reference\n",
      "\tNumber of tweets with a wanted tag: 1\n",
      "\tNumber of tweets without a wanted tag: 1\n",
      "\n",
      "\t*************\n",
      "\treference type: retweeted\n",
      "\tNumber of tweets with a wanted tag: 48\n",
      "\tNumber of tweets without a wanted tag: 7\n",
      "\n",
      "\t*************\n",
      "\treference type: quoted\n",
      "\tNumber of tweets with a wanted tag: 1\n",
      "\tNumber of tweets without a wanted tag: 0\n",
      "\n",
      "IchBinNichtHanna\n",
      "\t*************\n",
      "\treference type: quoted\n",
      "\tNumber of tweets with a wanted tag: 4\n",
      "\tNumber of tweets without a wanted tag: 1\n",
      "\n",
      "\t*************\n",
      "\treference type: replied_to\n",
      "\tNumber of tweets with a wanted tag: 4\n",
      "\tNumber of tweets without a wanted tag: 1\n",
      "\n",
      "\t*************\n",
      "\treference type: retweeted\n",
      "\tNumber of tweets with a wanted tag: 3\n",
      "\tNumber of tweets without a wanted tag: 3\n",
      "\n",
      "\t*************\n",
      "\treference type: no_reference\n",
      "\tNumber of tweets with a wanted tag: 4\n",
      "\tNumber of tweets without a wanted tag: 6\n",
      "\n",
      "WissZeitVG\n",
      "\t*************\n",
      "\treference type: quoted\n",
      "\tNumber of tweets with a wanted tag: 907\n",
      "\tNumber of tweets without a wanted tag: 170\n",
      "\n",
      "\t*************\n",
      "\treference type: retweeted\n",
      "\tNumber of tweets with a wanted tag: 5042\n",
      "\tNumber of tweets without a wanted tag: 5872\n",
      "\n",
      "\t*************\n",
      "\treference type: replied_to\n",
      "\tNumber of tweets with a wanted tag: 1005\n",
      "\tNumber of tweets without a wanted tag: 569\n",
      "\n",
      "\t*************\n",
      "\treference type: no_reference\n",
      "\tNumber of tweets with a wanted tag: 1037\n",
      "\tNumber of tweets without a wanted tag: 475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query in queries:\n",
    "    print(query)\n",
    "    \n",
    "    # read the search query hasthags\n",
    "    wanted_tags = []\n",
    "    with open(join('hashtags', '{}.txt'.format(query)), 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            wanted_tags.append(line.strip('\\n'))\n",
    "    wanted_tags = set(wanted_tags)\n",
    "        \n",
    "    tweets = pd.read_csv(join('../data/tweets', '{}.csv'.format(query)),\n",
    "                         low_memory=False)\n",
    "    tweets['hashtags'] = tweets['entities.hashtags'].apply(extract_hashtags)\n",
    "    tweets['reference_type'] = tweets['referenced_tweets'].apply(extract_reference_type)\n",
    "    tweets['wanted_tag'] = tweets['hashtags'].apply(check_wanted_tag)\n",
    "    \n",
    "    for reference_type in tweets['reference_type'].unique():\n",
    "        subset = tweets[tweets['reference_type'] == reference_type]\n",
    "        tag_found = subset[subset['wanted_tag'] == True]\n",
    "        tag_not_found = subset[subset['wanted_tag'] == False]\n",
    "        print('\\t*************')\n",
    "        print('\\treference type: {}'.format(reference_type))\n",
    "        print('\\tNumber of tweets with a wanted tag: {}'.format(len(tag_found)))\n",
    "        print('\\tNumber of tweets without a wanted tag: {}'.format(len(tag_not_found)))\n",
    "        print()\n",
    "        \n",
    "    tweets.to_csv(join('../data/tweets', '{}.csv'.format(query)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75857159-da0f-4a9a-93c6-9bd921fb95f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
